{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TorchCRF import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import BERT_CRF, BertCRFTagger\n",
    "from utils import *\n",
    "from dataloader import SeqLabeling_Dataset\n",
    "from config import args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "from seqeval.metrics import precision_score\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import recall_score\n",
    "from seqeval.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = args()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: dmis-lab/biobert-base-cased-v1.1.\n"
     ]
    }
   ],
   "source": [
    "print(f'Loading model: {paras.model_name}.')\n",
    "tokenizer = BertTokenizerFast.from_pretrained(paras.model_name)\n",
    "bert = BertModel.from_pretrained(paras.model_name, output_hidden_states=True)\n",
    "\n",
    "vocab_dict = tokenizer.get_vocab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SeqLabeling_Dataset(paras.train_data, paras.label_file, vocab_dict)\n",
    "label_to_index = train_dataset.label_to_index\n",
    "index_to_label = train_dataset.index_to_label\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=paras.batch_size,\n",
    "                                shuffle=paras.shuffle, drop_last=paras.drop_last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_crf_tagger = BertCRFTagger(bert, paras.hidden_size, paras.num_tags,\n",
    "                                paras.droupout_prob).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(bert_crf_tagger.parameters(), lr=paras.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PAD'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e9c428fa8b8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mbatch_max_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         batch_label_pad = label_padding(batch_max_length, batch_label_list,\n\u001b[1;32m---> 35\u001b[1;33m                                         label_to_index)\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mbatch_label_pad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_label_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\AGAC_NER\\src\\utils.py\u001b[0m in \u001b[0;36mlabel_padding\u001b[1;34m(batch_max_length, batch_label_list, label_to_index)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mout_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_to_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'O'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mpad_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_to_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PAD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mbatch_label_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_label_to_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_label_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_to_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PAD'"
     ]
    }
   ],
   "source": [
    "# train\n",
    "best_loss = 0\n",
    "for epoch in range(paras.num_train_epochs):\n",
    "    epoch_loss = 0\n",
    "    bert_crf_tagger.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_data, batch_label = batch\n",
    "        batch_data_list = [ data.split('&&&') for data in batch_data ]\n",
    "        batch_label_list = [ label.split('&&&') for label in batch_label ]\n",
    "\n",
    "        input_ids, mask = batch_data_processing(batch_data_list, paras.max_length,\n",
    "                                                        vocab_dict.get('[PAD]'),\n",
    "                                                        vocab_dict.get('[CLS]'),\n",
    "                                                        vocab_dict.get('[SEP]'))\n",
    "\n",
    "        input_ids = input_ids.to(device)\n",
    "        mask = mask.to(device)\n",
    "\n",
    "        # break\n",
    "        # encoded_input = tokenizer(batch_data_list,\n",
    "        #                           return_offsets_mapping=True,\n",
    "        #                           max_length=paras.max_length,\n",
    "        #                           truncation=True,\n",
    "        #                           is_split_into_words=True,\n",
    "        #                           padding=True,\n",
    "        #                           return_tensors='pt').to(device)\n",
    "\n",
    "        # input_ids = encoded_input['input_ids']\n",
    "        # mask = encoded_input['attention_mask'].byte()\n",
    "\n",
    "        batch_max_length = input_ids.shape[1]\n",
    "        batch_label_pad = label_padding(batch_max_length, batch_label_list,\n",
    "                                        label_to_index)\n",
    "\n",
    "        batch_label_pad = torch.LongTensor(batch_label_pad)\n",
    "        break\n",
    "\n",
    "        loss = bert_crf_tagger(input_ids, mask, batch_label_pad)\n",
    "\n",
    "        epoch_loss += loss.detach().cpu().item()\n",
    "\n",
    "        logger.info(f'epoch: {epoch}, step: {step}, loss: {loss:.4f}')\n",
    "        # acc, precision, recall, f1 = evaluation(bert_crf_tagger, test_dataloader,\n",
    "        #                                         index_to_label, tokenizer, paras)\n",
    "        # logger.info(f'ACC.: {acc:.4f}, Precision: {precision:.4f}, '\n",
    "        #             f'Recall: {recall:.4f}, F1-score: {f1:.4f}')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.shape, mask.shape, batch_label_pad.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids[0].shape, mask[0].sum(),batch_label_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = [tokenizer.decode(token) for token in input_ids[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-Reg': 0, 'I-Var': 1, 'B-Interaction': 2, 'B-CPA': 3, 'B-NegReg': 4, 'B-Pathway': 5, '[PAD]': 6, 'I-Pathway': 7, 'I-Disease': 8, 'I-MPA': 9, 'I-PosReg': 10, 'B-MPA': 11, 'I-CPA': 12, 'B-Protein': 13, 'I-Interaction': 14, 'I-NegReg': 15, 'B-Gene': 16, 'I-Protein': 17, 'B-Reg': 18, 'I-Gene': 19, 'I-Enzyme': 20, 'O': 21, 'B-PosReg': 22, 'B-Disease': 23, 'B-Var': 24, 'B-Enzyme': 25}\n"
     ]
    }
   ],
   "source": [
    "#print(token_list)\n",
    "print(label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_index(batch_label_list: list, label_to_index: dict):\n",
    "    batch_label_idx = []\n",
    "    for label_list in batch_label_list:\n",
    "        batch_label_idx.append([label_to_index[label] for label in label_list])\n",
    "    return batch_label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_padding(seq_max_length,batch_max_length: int, batch_label_list: list,\n",
    "                  label_to_index:dict, return_tensor=True):\n",
    "    \n",
    "    if batch_max_length > seq_max_length:\n",
    "        max_length = max_length\n",
    "    else:\n",
    "        max_length = batch_max_length\n",
    "    \n",
    "    pad_idx = label_to_index['[PAD]']\n",
    "    batch_label_idx = convert_label_to_index(batch_label_list, label_to_index)\n",
    "\n",
    "    batch_label_pad = []\n",
    "    for label_list in batch_label_idx:\n",
    "        if len(label_list) > (max_length-2):\n",
    "            label_list = label_list[:max_length-2]\n",
    "            label_list.insert(0, pad_idx)\n",
    "            label_list.append(pad_idx)\n",
    "            batch_label_pad.append(label_list)\n",
    "        else:\n",
    "            label_list.insert(0, pad_idx)\n",
    "            label_list.append(pad_idx)\n",
    "            label_list = label_list + ([pad_idx]*(max_length-len(label_list)))\n",
    "            batch_label_pad.append(label_list)\n",
    "    \n",
    "    if return_tensor:\n",
    "        return torch.LongTensor(batch_label_pad)\n",
    "    \n",
    "    return batch_label_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 45)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_label_list),len(batch_label_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_label_pad = label_padding(paras.max_length, batch_max_length,\n",
    "                                batch_label_list,label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_label_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [index_to_label[int(index)] for index in batch_label_pad[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Gene', 'O', 'B-NegReg', 'B-Var', 'O', 'O', 'B-PosReg', 'I-PosReg', 'O', 'B-MPA', 'I-MPA', 'O', 'B-PosReg', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MPA', 'I-MPA', 'O', 'O', 'O', 'O']\n",
      "['[PAD]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Gene', 'O', 'B-NegReg', 'B-Var', 'O', 'O', 'B-PosReg', 'I-PosReg', 'O', 'B-MPA', 'I-MPA', 'O', 'B-PosReg', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MPA', 'I-MPA', 'O', 'O', 'O', 'O', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " tensor([ 6, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 16, 21,  4, 24, 21, 21, 22, 10, 21, 11,  9, 21, 22, 21, 21, 21,\n",
       "         21, 21, 21, 21, 11,  9, 21, 21, 21, 21,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "          6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "          6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "          6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "          6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "          6,  6]),\n",
       " None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(batch_label_list[0]), batch_label_pad[0], print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [PAD]\n",
      "Further O\n",
      "clinical O\n",
      "studies O\n",
      "to O\n",
      "confirm O\n",
      "this O\n",
      "relationship O\n",
      "are O\n",
      "[UNK] O\n",
      ". O\n",
      "[UNK] O\n",
      "[UNK] O\n",
      "[UNK] O\n",
      "but O\n",
      "not O\n",
      "[UNK] O\n",
      "[UNK] O\n",
      "in O\n",
      "[UNK] O\n",
      "[UNK] O\n",
      "of O\n",
      "human O\n",
      "lung O\n",
      "cancer O\n",
      "[UNK] O\n",
      "- O\n",
      "[UNK] O\n",
      "cells O\n",
      ". O\n",
      "More O\n",
      "than O\n",
      "half O\n",
      "of O\n",
      "all O\n",
      "human B-Disease\n",
      "[UNK] I-Disease\n",
      "are O\n",
      "associated B-Reg\n",
      "with O\n",
      "mutations B-Var\n",
      "of O\n",
      "the O\n",
      "[UNK] B-Gene\n",
      "gene O\n",
      ". O\n",
      "[SEP] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n",
      "[PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "example_idx = 1\n",
    "token_list = [tokenizer.decode(token) for token in input_ids[example_idx]]\n",
    "label_list = [index_to_label[int(index)] for index in batch_label_pad[example_idx]]\n",
    "for i in range(len(label_list)):\n",
    "    print(token_list[i], label_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data_tensor, mask = batch_data_processing(batch_data_list, 128, vocab_dict.get('[PAD]'), vocab_dict.get('[CLS]'),vocab_dict.get('[SEP]'))\n",
    "batch_max_length = batch_data_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 28 tensor(28) 28\n",
      "79 79 tensor(79) 79\n",
      "23 23 tensor(23) 23\n",
      "85 85 tensor(85) 85\n",
      "60 60 tensor(60) 60\n",
      "34 34 tensor(34) 34\n",
      "40 40 tensor(40) 40\n",
      "28 28 tensor(28) 28\n",
      "132 132 tensor(128) 128\n",
      "71 71 tensor(71) 71\n",
      "119 119 tensor(119) 119\n",
      "101 101 tensor(101) 101\n",
      "43 43 tensor(43) 43\n",
      "52 52 tensor(52) 52\n",
      "30 30 tensor(30) 30\n",
      "64 64 tensor(64) 64\n",
      "27 27 tensor(27) 27\n",
      "122 122 tensor(122) 122\n",
      "200 200 tensor(128) 128\n",
      "57 57 tensor(57) 57\n",
      "66 66 tensor(66) 66\n",
      "43 43 tensor(43) 43\n",
      "30 30 tensor(30) 30\n",
      "38 38 tensor(38) 38\n",
      "299 299 tensor(128) 128\n",
      "22 22 tensor(22) 22\n",
      "76 76 tensor(76) 76\n",
      "29 29 tensor(29) 29\n",
      "254 254 tensor(128) 128\n",
      "69 69 tensor(69) 69\n",
      "240 240 tensor(128) 128\n",
      "166 166 tensor(128) 128\n"
     ]
    }
   ],
   "source": [
    "len(batch_data_list), len(batch_label_list)\n",
    "\n",
    "for i in range(len(batch_data_list)):\n",
    "    print(len(batch_data_list[i]), len(batch_label_list[i]), mask[i].sum(), len(predict_result[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_index_to_label_single(index_list: list, index_to_label: dict):\n",
    "    return [index_to_label[idx] for idx in index_list]\n",
    "def convert_index_to_token_single(index_list: list, tokenizer):\n",
    "    return [tokenizer.decode(index) for index in index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 128 128\n"
     ]
    }
   ],
   "source": [
    "data_exp = input_ids[0]\n",
    "label_exp = batch_label_pad[0]\n",
    "mask_exp = mask[0]\n",
    "predict_label = bert_crf_tagger(data_exp.unsqueeze(0), mask_exp.unsqueeze(0))\n",
    "print(len(data_exp), len(label_exp), len(mask_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = convert_index_to_token_single(data_exp, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'This',\n",
       " 'effect',\n",
       " 'was',\n",
       " 'not',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'enhanced',\n",
       " 'β',\n",
       " '-',\n",
       " 'cell',\n",
       " 'proliferation',\n",
       " 'or',\n",
       " 'mass',\n",
       " '.',\n",
       " 'Our',\n",
       " 'data',\n",
       " 'suggest',\n",
       " 'that',\n",
       " 'the',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'mutation',\n",
       " 'may',\n",
       " '[UNK]',\n",
       " 'beneficial',\n",
       " 'effects',\n",
       " 'on',\n",
       " 'glucose',\n",
       " 'metabolism',\n",
       " 'by',\n",
       " 'increasing',\n",
       " 'the',\n",
       " 'capacity',\n",
       " 'of',\n",
       " 'β',\n",
       " '-',\n",
       " 'cells',\n",
       " 'to',\n",
       " '[UNK]',\n",
       " 'insulin',\n",
       " 'under',\n",
       " '[UNK]',\n",
       " 'conditions',\n",
       " '.',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = bert_crf_tagger(data_exp.unsqueeze_(0), mask_exp.unsqueeze_(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[13,\n",
       "  13,\n",
       "  20,\n",
       "  13,\n",
       "  0,\n",
       "  19,\n",
       "  13,\n",
       "  0,\n",
       "  19,\n",
       "  23,\n",
       "  23,\n",
       "  12,\n",
       "  20,\n",
       "  0,\n",
       "  7,\n",
       "  17,\n",
       "  12,\n",
       "  20,\n",
       "  20,\n",
       "  4,\n",
       "  0,\n",
       "  17,\n",
       "  17,\n",
       "  3,\n",
       "  13,\n",
       "  13,\n",
       "  17,\n",
       "  12,\n",
       "  20,\n",
       "  23,\n",
       "  12,\n",
       "  13,\n",
       "  0,\n",
       "  20,\n",
       "  19,\n",
       "  17,\n",
       "  0,\n",
       "  23,\n",
       "  10,\n",
       "  19,\n",
       "  0,\n",
       "  3,\n",
       "  19,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = [tokenizer.decode(token) for token in data_exp]\n",
    "label_list = [index_to_label[index] for index in label_exp]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test predict_result and evaluation\n",
    "predict_result = bert_crf_tagger(batch_data_tensor, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_truncation(batch_label_list: list, max_length: int):\n",
    "    process_label_list = []\n",
    "    for label_list in batch_label_list:\n",
    "        if len(label_list) > max_length:\n",
    "            process_label_list.append(label_list[:max_length-2])\n",
    "        else:\n",
    "            process_label_list.append(label_list[:-2])\n",
    "    return process_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label_list = convert_index_to_label(predict_result, index_to_label)\n",
    "ture_label_list = label_truncation(batch_label_list, batch_max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 26)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_result[0]), len(predict_label_list[0]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 26)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_label_list[0]), len(ture_label_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predict_label_list)):\n",
    "    if len(predict_label_list[i]) != len(ture_label_list[i]):\n",
    "        print(len(predict_label_list[i]), len(ture_label_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 23)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_data_list[2]), len(batch_label_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = [tokenizer.decode(idx) for idx in input_ids[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13254"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict['RNA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The [CLS]\n",
      "main the\n",
      "clinical main\n",
      "and clinical\n",
      "[UNK] and\n",
      "features [UNK]\n",
      "of features\n",
      "[UNK] of\n",
      "are [UNK]\n",
      "progressive are\n",
      "intention progressive\n",
      "[UNK] intention\n",
      "and [UNK]\n",
      "[UNK] and\n",
      "[UNK] [UNK]\n",
      "associated [UNK]\n",
      "with associated\n",
      "brain with\n",
      "[UNK] brain\n",
      ", [UNK]\n",
      "[UNK] ,\n",
      "cell [UNK]\n",
      "loss cell\n",
      "and loss\n",
      "presence and\n",
      "of presence\n",
      "[UNK] of\n",
      "- [UNK]\n",
      "positive -\n",
      "[UNK] positive\n",
      "[UNK] [UNK]\n",
      "in [UNK]\n",
      "both in\n",
      "neurons both\n",
      "and neurons\n",
      "[UNK] and\n",
      ". [UNK]\n",
      "At .\n",
      "the at\n",
      "molecular the\n",
      "level molecular\n",
      ", level\n",
      "[UNK] ,\n",
      "is [UNK]\n",
      "characterized is\n",
      "by characterized\n",
      "increased by\n",
      "expression increased\n",
      "of expression\n",
      "[UNK] of\n",
      "sense [UNK]\n",
      "and sense\n",
      "[UNK] and\n",
      "RNA [UNK]\n",
      "containing r\n",
      "expanded ##na\n",
      "[UNK] containing\n",
      "or expanded\n",
      "[UNK] [UNK]\n",
      "repeats or\n",
      ", [UNK]\n",
      "respectively repeats\n",
      ". ,\n",
      "Here respectively\n",
      ", .\n",
      "we here\n",
      "discuss ,\n",
      "the we\n",
      "[UNK] discuss\n",
      "molecular the\n",
      "mechanisms [UNK]\n",
      "underlying molecular\n",
      "[UNK] mechanisms\n",
      "and underlying\n",
      "notably [UNK]\n",
      "recent and\n",
      "reports notably\n",
      "that recent\n",
      "expanded reports\n",
      "[UNK] that\n",
      "and expanded\n",
      "[UNK] [UNK]\n",
      "repeats and\n",
      "may [UNK]\n",
      "be repeats\n",
      "[UNK] may\n",
      "through be\n",
      "[UNK] [UNK]\n",
      "translation through\n",
      "into [UNK]\n",
      "toxic translation\n",
      "proteins into\n",
      ". toxic\n",
      "[UNK] proteins\n",
      "variants .\n",
      "in [UNK]\n",
      "[UNK] variants\n",
      "are in\n",
      "prevalent [UNK]\n",
      "in are\n",
      "[UNK] prevalent\n",
      "cases in\n",
      "of [UNK]\n",
      "[UNK] cases\n",
      "valve of\n",
      "[UNK] [UNK]\n",
      ". valve\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(batch_data_list[2])):\n",
    "    print(batch_data_list[2][i], token_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_result[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = [tokenizer.decode(idx) for idx in input_ids[2]]\n",
    "token_list.count('[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 110, 108, 107)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_list), len(predict_result[2]), len(predict_label_list[2]), len(batch_label_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2,3],[1,2,3,4], [1,2,3], [1,2,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-b5c8abcf1819>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mis_split_into_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                 return_tensors='pt')\n\u001b[0m",
      "\u001b[1;32md:\\pto_env_test\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2213\u001b[0m             )\n\u001b[0;32m   2214\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2215\u001b[1;33m             \u001b[1;34m\"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2216\u001b[0m             \u001b[1;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2217\u001b[0m         )\n",
      "\u001b[1;31mAssertionError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(a,\n",
    "                return_offsets_mapping=True,\n",
    "                max_length=paras.max_length,\n",
    "                truncation=True,\n",
    "                is_split_into_words=True,\n",
    "                padding=True,\n",
    "                return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list.count('[UNK]'), len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_truncation(batch_label_list: list, max_length: int):\n",
    "    process_label_list = []\n",
    "    for label_list in batch_label_list:\n",
    "        if len(label_list) > max_length:\n",
    "            process_label_list.append(label_list[:max_length-2])\n",
    "        else:\n",
    "            process_label_list.append(label_list)\n",
    "    return process_label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label_list = convert_index_to_label(predict_result, index_to_label)\n",
    "ture_label_list = label_truncation(batch_label_list, batch_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 79 79\n",
      "126 126 171\n",
      "108 107 107\n",
      "33 32 32\n",
      "126 126 149\n",
      "68 67 67\n",
      "126 126 136\n",
      "30 30 30\n",
      "126 126 169\n",
      "15 15 15\n",
      "126 126 384\n",
      "126 126 292\n",
      "126 126 191\n",
      "72 72 72\n",
      "126 126 130\n",
      "12 12 12\n",
      "34 34 34\n",
      "90 88 88\n",
      "126 126 288\n",
      "45 44 44\n",
      "82 82 82\n",
      "57 57 57\n",
      "59 59 59\n",
      "46 45 45\n",
      "21 21 21\n",
      "19 19 19\n",
      "86 85 85\n",
      "62 62 62\n",
      "57 57 57\n",
      "17 17 17\n",
      "77 75 75\n",
      "35 34 34\n"
     ]
    }
   ],
   "source": [
    "#predict_label_list\n",
    "#ture_label_list\n",
    "for i in range(len(predict_label_list)):\n",
    "    print(len(predict_label_list[i]), len(ture_label_list[i]), len(batch_label_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_result), len(batch_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_index_to_label(batch_index_list: list, index_to_label: dict,\n",
    "                           del_special_token=True):\n",
    "    batch_label_list = []\n",
    "    for idx_list in batch_index_list:\n",
    "        label_list = [index_to_label[idx] for idx in idx_list]\n",
    "        if del_special_token:\n",
    "            label_list = label_list[1:-1]\n",
    "        batch_label_list.append(label_list)\n",
    "    return batch_label_list\n",
    "\n",
    "def label_truncation(batch_label_list: list, max_length: int):\n",
    "    pro_label_list = []\n",
    "    for label_list in batch_label_list:\n",
    "        if len(label_list) > max_length:\n",
    "            pro_label_list.append(label_list[:max_length-2])\n",
    "        else:\n",
    "            pro_label_list.append(label_list)\n",
    "    return pro_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label_list = convert_index_to_label(predict_result, index_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label_list = convert_index_to_label(predict_result, index_to_label)\n",
    "ture_label_list = label_truncation(batch_label_list, batch_max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_label_list), len(ture_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "126\n",
      "31\n",
      "126\n",
      "126\n",
      "44\n",
      "24\n",
      "126\n",
      "123\n",
      "126\n",
      "69\n",
      "126\n",
      "126\n",
      "126\n",
      "126\n",
      "62\n",
      "79\n",
      "126\n",
      "43\n",
      "57\n",
      "126\n",
      "126\n",
      "69\n",
      "126\n",
      "37\n",
      "126\n",
      "44\n",
      "50\n",
      "126\n",
      "42\n",
      "11\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "for i in predict_label_list:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred_label = []\n",
    "total_ture_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for predict_list, ture_list in zip(predict_label_list, ture_label_list):\n",
    "    if len(predict_list) != len(ture_list):\n",
    "        print(len(predict_list), len(ture_list))\n",
    "        continue\n",
    "        \n",
    "    total_pred_label.append(predict_list)\n",
    "    total_ture_label.append(ture_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_pred_label), len(total_ture_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['O','O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
    "'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
    "     'O', 'O'\n",
    ", 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'\n",
    ", 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
    " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
    "'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "\n",
    "b = ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
    "'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
    "     'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'\n",
    ", 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
    " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
    "'O', 'O', 'O', 'O', 'B-Var', 'I-Var', 'I-Var', 'I-Var', 'I-Var', 'I-Var', 'I-Var', 'I-Var',\n",
    " 'I-Var', 'I-Var', 'B-Reg', 'B-Disease', 'I-Disease', 'I-Disease', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 128)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a), len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03138485680659082"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(total_ture_label, total_pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012244897959183673"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(ture_label_list, predict_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03225806451612903"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(ture_label_list, predict_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023594180102241443"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ture_label_list, predict_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 39 39 39\n",
      "128 126 126 126\n",
      "33 31 31 31\n",
      "128 126 209 126\n",
      "128 126 239 126\n",
      "46 44 44 44\n",
      "26 24 24 24\n",
      "128 126 141 126\n",
      "125 123 123 123\n",
      "128 126 266 126\n",
      "71 69 69 69\n",
      "128 126 179 126\n",
      "128 126 256 126\n",
      "128 126 179 126\n",
      "128 126 297 126\n",
      "64 62 62 62\n",
      "81 79 79 79\n",
      "128 126 311 126\n",
      "45 43 43 43\n",
      "59 57 57 57\n",
      "128 126 241 126\n",
      "128 126 376 126\n",
      "71 69 69 69\n",
      "128 126 308 126\n",
      "39 37 37 37\n",
      "128 126 306 126\n",
      "46 44 44 44\n",
      "52 50 50 50\n",
      "128 126 414 126\n",
      "44 42 42 42\n",
      "13 11 11 11\n",
      "35 33 33 33\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predict_label_list)):\n",
    "    print(len(predict_result[i]), len(predict_label_list[i]), len(batch_label_list[i]),\n",
    "         len(ture_label_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-CPA': 0,\n",
       " 'I-Reg': 1,\n",
       " 'B-Disease': 2,\n",
       " 'B-PosReg': 3,\n",
       " 'I-PosReg': 4,\n",
       " 'I-MPA': 5,\n",
       " 'B-CPA': 6,\n",
       " 'I-Var': 7,\n",
       " 'I-Interaction': 8,\n",
       " 'B-Interaction': 9,\n",
       " 'I-Disease': 10,\n",
       " 'B-NegReg': 11,\n",
       " 'I-Pathway': 12,\n",
       " 'B-Enzyme': 13,\n",
       " 'I-Enzyme': 14,\n",
       " 'B-MPA': 15,\n",
       " 'I-Gene': 16,\n",
       " 'B-Protein': 17,\n",
       " 'B-Pathway': 18,\n",
       " 'B-Reg': 19,\n",
       " 'B-Gene': 20,\n",
       " 'O': 21,\n",
       " 'B-Var': 22,\n",
       " 'I-NegReg': 23,\n",
       " 'I-Protein': 24}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-08 18:39:54\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-04-08 18:40:43'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
